{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "**Note:**\n",
    "\n",
    "You can download this demo as a Jupyter notebook [here](https://github.com/ejhigson/dyPolyChord/blob/master/docs/demo.ipynb) and run it interactively yourself.\n",
    "</div>\n",
    "\n",
    "# dyPolyChord Demo\n",
    "\n",
    "The main user-facing function is ``dyPolyChord.run_dypolychord``, which performs dynamic nested sampling.\n",
    "\n",
    "Likelihoods and priors are specified as a python callable, which can be used to run PolyChord on the likelihood and prior with an input settings dictionary. Tools for making such a callable are provided in ``pypolychord_utils.py`` (python likelihoods and priors) and ``polychord_utils.py`` (compiled C++ and Fortran likelihoods and priors).\n",
    "\n",
    "In addition the user can specify PolyChord settings (as a dictionary), and can choose whether to prioritise parameter estimation or evidence calculation via the ``dynamic_goal`` argument (see the [dynamic nested sampling paper](https://arxiv.org/abs/1704.03459) for an explanation)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compiled (C++ or Fortran) likelihoods and priors\n",
    "\n",
    "C++ and Fortran likelihoods used by PolyChord can also be used by ``dyPolyChord`` (they must be able to read settings from .ini files). These must be compiled to executables within the PolyChord directory, via commands such as\n",
    "\n",
    "    $ make gaussain  # PolyChord gaussian example\n",
    "\n",
    "or\n",
    "\n",
    "    $ make polychord_CC_ini  # PolyChord template C++ likelihood which reads .ini file\n",
    "\n",
    "See the PolyChord README for more details. ``dyPolyChord`` simply needs the file path to the executable, which it runs via ``os.system`` - settings are specified by writing temporary .ini files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dyPolyChord.polychord_utils\n",
    "import dyPolyChord\n",
    "\n",
    "\n",
    "# Definte the distribution to sample (likelihood, prior, number of dimensions)\n",
    "ex_command = './gaussian'  # path to compiled executable likelihood\n",
    "# The prior must be specified as strings via .ini files. get_prior_block_str provides a\n",
    "# convenient function for making such PolyChord-formatted strings. See its docstring and\n",
    "# the PolyChord documentation for more details\n",
    "ndim = 10\n",
    "prior_str = dyPolyChord.polychord_utils.get_prior_block_str(\n",
    "    'gaussian', [0.0, 10.0], ndim)\n",
    "\n",
    "# Make a callable for running PolyChord\n",
    "my_callable = dyPolyChord.polychord_utils.RunCompiledPolyChord(\n",
    "    ex_command, prior_str)\n",
    "\n",
    "# Specify sampler settings (see run_dynamic_ns.py documentation for more details)\n",
    "dynamic_goal = 1.0  # whether to maximise parameter estimation or evidence accuracy. \n",
    "ninit = 50          # number of live points to use in initial exploratory run.\n",
    "nlive_const = 200   # total computational budget is the same as standard nested sampling with nlive_const live points. \n",
    "settings_dict = {'file_root': 'gaussian',\n",
    "                 'base_dir': 'chains',\n",
    "                 'seed': 1}\n",
    "\n",
    "# Run dyPolyChord\n",
    "dyPolyChord.run_dypolychord(my_callable, dynamic_goal, settings_dict,\n",
    "                            ninit=ninit, nlive_const=nlive_const)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python likelihoods and priors\n",
    "\n",
    "Python likelihoods and priors must be defined as functions, just as for running PyPolyChord (PolyChord's python wrapper). Otherwise the process is very similar to that with compiled likelihoods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dyPolyChord.python_likelihoods as likelihoods  # Import some example python likelihoods\n",
    "import dyPolyChord.python_priors as priors  # Import some example python priors\n",
    "import dyPolyChord.pypolychord_utils\n",
    "import dyPolyChord\n",
    "\n",
    "\n",
    "# Definte the distribution to sample (likelihood, prior, number of dimensions)\n",
    "ndim = 10\n",
    "likelihood = likelihoods.Gaussian(sigma=1.0)\n",
    "prior = priors.Gaussian(sigma=10.0)\n",
    "\n",
    "# Make a callable for running PolyChord\n",
    "my_callable = dyPolyChord.pypolychord_utils.RunPyPolyChord(\n",
    "    likelihood, prior, ndim)\n",
    "\n",
    "# Specify sampler settings (see run_dynamic_ns.py documentation for more details)\n",
    "dynamic_goal = 1.0  # whether to maximise parameter estimation or evidence accuracy. \n",
    "ninit = 50          # number of live points to use in initial exploratory run.\n",
    "nlive_const = 200   # total computational budget is the same as standard nested sampling with nlive_const live points. \n",
    "settings_dict = {'file_root': 'gaussian',\n",
    "                 'base_dir': 'chains',\n",
    "                 'seed': 1}\n",
    "\n",
    "# Run dyPolyChord\n",
    "dyPolyChord.run_dypolychord(my_callable, dynamic_goal, settings_dict,\n",
    "                            ninit=ninit, nlive_const=nlive_const)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallelisation\n",
    "\n",
    "\n",
    "#### Compiled likelihoods and priors\n",
    "\n",
    "To run compiled likelihoods in parallel with MPI, specify an mpirun command in the `mpi_str` argument when initializing your `RunPyPolyChord` object. For example to run with 8 processes, use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_callable = dyPolyChord.polychord_utils.RunCompiledPolyChord(\n",
    "    ex_command, prior_str, mpi_str='mpirun -np 8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The callable can then be used with `run_dypolychord` as normal.\n",
    "\n",
    "#### Python likelihoods and priors\n",
    "\n",
    "You must import `mpi4py`, create an `MPI.COMM_WORLD` object and pass it to `run_dypolychord` as an argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpi4py import MPI\n",
    "comm = MPI.COMM_WORLD\n",
    "\n",
    "dyPolyChord.run_dypolychord(my_callable, dynamic_goal, settings_dict,\n",
    "                            ninit=ninit, nlive_const=nlive_const, comm=comm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can then run your script with mpirun:\n",
    "\n",
    "    $ mpirun -np 8 my_dypolychord_script.py\n",
    "\n",
    "\n",
    "#### Random seeding\n",
    "\n",
    "Due to the unpredictable order in which slave processes are called by PolyChord, results will not me reproducible when running with more than one MPI process even when a random seed is used.\n",
    "\n",
    "\n",
    "#### Repeated runs\n",
    "\n",
    "If you want to perform a number of independent `dyPolyChord` calculations (such as repeating the same calculation many times) then, as this is \"embarrassingly parallel\", you don't need MPI and can instead perform many `dyPolyChord` runs in parallel using python's `concurrent.futures`. This also allows reliable random seeding for reproducible results. Note that for this to work PolyChord must be installed without MPI. For an example of this type of usage, see the code used to make the results for the dynamic nested sampling paper (https://github.com/ejhigson/dynamic_nested_sampling_paper)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking the output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running ``dyPolyChord`` produces PolyChord-format output files in `settings['base_dir']`. These output files can be analysed in the same way as other PolyChord output files. One convenient package for doing this in python is ``nestcheck`` (see http://nestcheck.readthedocs.io/en/latest/ for more details):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nestcheck.data_processing\n",
    "\n",
    "# load the run\n",
    "run = nestcheck.data_processing.process_polychord_run(\n",
    "    settings_dict['file_root'], settings_dict['base_dir'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an example, lets use ``nestcheck`` to check ``dyPolyChord``'s allocation of live points roughly matches the distribution of posterior mass for this likelihood and prior.\n",
    "\n",
    "For a detailed explanation of this type of plot see Figure 4 in the dynamic nested sampling paper ([Higson et al., 2017](https://arxiv.org/abs/1704.03459)) and its caption. Note that in this case the estimated $\\log X$ values ($x$ co-ordinates) and the relative posterior mass line are estimated statistically from the run and are only approximate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import nestcheck.ns_run_utils\n",
    "\n",
    "logx = nestcheck.ns_run_utils.get_logx(run['nlive_array'])\n",
    "logw = logx + run['logl']\n",
    "w_rel = np.exp(logw - logw.max())\n",
    "\n",
    "# plot nlive and w_rel on same axis\n",
    "fig = plt.figure()\n",
    "ax1 = fig.add_subplot(111)\n",
    "ax2 = ax1.twinx()\n",
    "l1 = ax1.plot(logx, run['nlive_array'], label='number of live points', color='blue')\n",
    "l2 = ax2.plot(logx, w_rel, label='relative posterior mass', color='black', linestyle='dashed')\n",
    "ax1.set_xlabel('estimated $\\log X$')\n",
    "ax1.set_xlim(right=0.0)\n",
    "ax1.set_ylim(bottom=0.0)\n",
    "ax1.set_ylabel('number of live points')\n",
    "ax2.set_ylim(bottom=0.0)\n",
    "ax2.set_yticks([])\n",
    "ax2.set_ylabel('relative posterior mass')\n",
    "lines = l1 + l2\n",
    "ax1.legend(lines, [l.get_label() for l in lines], loc=0)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
